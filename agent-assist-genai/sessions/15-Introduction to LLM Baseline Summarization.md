# ðŸ“ LLM Baseline Summarization â€” Premium Notes

> Sleek, GitHubâ€‘ready documentation with image placeholders. This session covers capabilities, business value, configuration highlights, and includes a quiz with the correct answer.

---

## ðŸš€ Module Introduction: LLM Baseline Summarization
**LLM Baseline Summarization** is an Agent Assist feature that automatically generates a concise summary of a customer conversation. It works for **botâ†”human** and **humanâ†”human** dialogs. You can summarize using:
- A **preâ€‘trained LLM Baseline Summarization model** (focus of this lesson), or
- A **customâ€‘trained summarization model** on your own data (currently in limited preview in some environments).

> *(Insert your intro screenshot below)*

![llm-sum-intro](../screenshots/ADD_LATER.png)

---

## ðŸ§© Capabilities
- Produces **clear, structured conversation summaries** suitable for agent notes and case wrapâ€‘up
- Supports both **bot** and **human** interactions
- Offers configurable **summary sections** (see below) to standardize outputs across teams
- Designed to **save time**, improve **consistency**, and reduce **afterâ€‘call work (ACW)**

> *(Insert capabilities screenshot below)*

![llm-sum-capabilities](../screenshots/ADD_LATER.png)

---

## ðŸ’¼ Business Value (Observed)
Organizations adopting Baseline Summarization report:
- â±ï¸ **~10Ã— faster** throughput for **unedited** summaries (e.g., 80â€“100s â†’ **6â€“10s**)
- ðŸ“ **3Ã— faster** median time for **edited** summaries (**~25â€“30s**) vs manual writing
- ðŸ§° **Standardized format & tone** across agents â†’ easier QA and reporting

> *(Insert business value screenshot below)*

![llm-sum-business](../screenshots/ADD_LATER.png)

---

## ðŸ§± Summary Sections (Baseline Template)
You can mix & match the following predefined sections when configuring the Baseline model:

1. **Situation** â€” Core of the customerâ€™s query/concern; why they reached out.
2. **Action** â€” Steps the agent (or bot) took during the interaction.
3. **Resolution** â€” Final outcome (Yes / No / Partially resolved / N/A).
4. **Customer satisfaction** â€” Gauge of sentiment at end of chat (e.g., Satisfied/Unsatisfied).
5. **Reason for cancellation** â€” Used when a customer requests cancellation (use N/A otherwise).
6. **Entities** â€” Key valueâ€‘pairs extracted (product names, timeframes, IDs, etc.).

> *(Insert sections screenshot below)*

![llm-sum-sections](../screenshots/ADD_LATER.png)

---

## ðŸ§ª Quiz â€” LLM Baseline Summarization
**Passing score:** 80%

### Q1. What is the **primary benefit** of the Agent Assist Summarization feature?

**Choices:**
1) It reduces the time agents spend on summarizing conversations, leading to increased productivity.  
2) It summarizes previous similar conversations to assist the agent in finding a resolution quicker.  
3) It sends a summary report to the end user as a report of the interaction.  
4) It summarizes every sentence the customer speaks into a few words to speed up interactions.  

**âœ… Correct Answer:** **(1) It reduces the time agents spend on summarizing conversations, leading to increased productivity.**

**Why:** Baseline Summarization focuses on **saving agent time** and **standardizing** the afterâ€‘call summary of the **current conversation**, not mining historical chats or sending reports to end users.

---

## ðŸŸ¦ Quick Summary
- **LLM Baseline Summarization** autoâ€‘generates concise, structured summaries for botâ†”human and humanâ†”human conversations.
- Proved to deliver **~10Ã— faster** unedited summaries and **3Ã— faster** edited summaries.
- Configure **sections** (Situation, Action, Resolution, Customer satisfaction, Reason for cancellation, Entities) for standardized outputs.
- **Primary benefit:** it **reduces agent effort** on afterâ€‘call notes â†’ higher productivity and consistent quality.

---
